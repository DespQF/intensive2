{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание хода работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортим нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные и делаем предобработку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала очищаем пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из CSV-файла\n",
    "file_path = 'valid.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Определяем порог пропусков\n",
    "threshold = 0.1\n",
    "\n",
    "# Вычисляем долю пропусков для каждого столбца\n",
    "missing_fraction = data.isnull().mean()\n",
    "\n",
    "# Оставляем только те столбцы, где доля пропусков меньше или равна 70%\n",
    "cleaned_data = data.loc[:, missing_fraction <= threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем чистим нули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем порог значений\n",
    "threshold = 0.1\n",
    "\n",
    "# Создаем DataFrame без столбца 'target' для анализа\n",
    "data_without_target = data.drop(columns=['target'], errors='ignore')\n",
    "\n",
    "# Вычисляем долю значений, равных 0 для каждого столбца\n",
    "zero_fraction = (data_without_target == 0).mean()\n",
    "\n",
    "# Получаем список столбцов, которые нужно оставить\n",
    "columns_to_keep = zero_fraction[zero_fraction < threshold].index.tolist()\n",
    "\n",
    "# Проверяем, есть ли 'target' в исходных данных и добавляем его в список\n",
    "if 'target' in data.columns:\n",
    "    columns_to_keep.append('target')\n",
    "\n",
    "# Оставляем только те столбцы\n",
    "cleaned_data = data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чистим не именно пропуски, а null значения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем порог пропусков\n",
    "threshold = 0.1\n",
    "\n",
    "# Вычисляем долю пропусков для каждой строки\n",
    "missing_fraction = data.isnull().mean(axis=1)\n",
    "\n",
    "# Удаляем строки, где доля пропусков больше 10%\n",
    "cleaned_data = data[missing_fraction <= threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ощищаем черезмерное количество единичных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_with_high_one_percentage(df, threshold=0.3):\n",
    "    # Определяем количество строк в DataFrame\n",
    "    total_rows = df.shape[0]\n",
    "\n",
    "    # Находим столбцы, которые нужно удалить\n",
    "    columns_to_drop = []\n",
    "    for column in df.columns:\n",
    "        # Вычисляем процент значений равных 1.0\n",
    "        percentage_of_ones = (df[column] == 1.0).mean()\n",
    "        if percentage_of_ones > threshold:\n",
    "            columns_to_drop.append(column)\n",
    "            print(f\"Столбец '{column}' будет удален (процент 1.0: {percentage_of_ones * 100:.2f}%)\")\n",
    "\n",
    "    # Удаляем столбцы\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Применяем функцию\n",
    "df_cleaned = drop_columns_with_high_one_percentage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертируем данные во float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns_to_float(df):\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            # Пробуем преобразовать столбец в float\n",
    "            df[column] = df[column].astype(float)\n",
    "        except ValueError:\n",
    "            # Если возникает ошибка, столбец не может быть преобразован\n",
    "            print(f\"Столбец '{column}' не может быть преобразован в float.\")\n",
    "    return df\n",
    "\n",
    "# Применяем функцию\n",
    "df_converted = convert_columns_to_float(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очищаем дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(row, df):\n",
    "    return (df == row).sum(axis=1)\n",
    "\n",
    "# Создаем маску для удаления строк\n",
    "rows_to_drop = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    match_count = count_matches(row, data)\n",
    "    # Удаляем текущую строку из подсчета совпадений\n",
    "    match_count = match_count.drop(index)\n",
    "    if (match_count > 10).any():  # Если есть строка с более чем 10 совпадениями\n",
    "        rows_to_drop.append(index)\n",
    "\n",
    "# Удаляем строки из DataFrame\n",
    "cleaned_data = data.drop(index=rows_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее отправляем данные в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "file_path = 'vcleaned_file_without_duplicates.csv'\n",
    "valid = pd.read_csv(file_path)\n",
    "file_path = 'cleaned_file_without_duplicates.csv'\n",
    "train = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Загрузка Train\n",
    "X_train = train.drop(columns='target')\n",
    "y_train = train['target']\n",
    "X_test = valid.drop(columns='target')\n",
    "y_test = valid['target']\n",
    "\n",
    "# инициализация и обучение модели\n",
    "rf_classifier = RandomForestClassifier(min_samples_leaf=5, n_estimators=100, random_state=384)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# предсказание вероятностей\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "\n",
    "# построение ROC кривой\n",
    "plt.plot(fpr, tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('ROC.png')\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC: %.3f\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![My Image](ROC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC: 0.725\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
